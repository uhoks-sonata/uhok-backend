#!/usr/bin/env python3
"""
ë°±ì—”ë“œì—ì„œ ì›ê²© ML ì„œë¹„ìŠ¤ ì—°ë™ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import os
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
os.environ["ML_MODE"] = "remote_embed"
os.environ["ML_INFERENCE_URL"] = "http://localhost:8001"
os.environ["ML_TIMEOUT"] = "5.0"
os.environ["ML_RETRIES"] = "2"

async def test_remote_ml_adapter():
    """ì›ê²© ML ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ë°±ì—”ë“œ ì›ê²© ML ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        # 1. ì–´ëŒ‘í„° ì„í¬íŠ¸ ë° ìƒì„±
        print("ğŸ“¦ ì›ê²© ML ì–´ëŒ‘í„° ì„í¬íŠ¸...")
        from services.recipe.utils.remote_ml_adapter import RemoteMLAdapter, MLServiceHealthChecker
        
        adapter = RemoteMLAdapter()
        print("âœ… ì–´ëŒ‘í„° ìƒì„± ì„±ê³µ")
        
        # 2. í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸
        print("\nğŸ” ML ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬...")
        health_info = await MLServiceHealthChecker.check_health()
        print(f"í—¬ìŠ¤ì²´í¬ ê²°ê³¼: {health_info}")
        
        if health_info.get("status") != "ok":
            print("âŒ ML ì„œë¹„ìŠ¤ê°€ ì •ìƒ ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤")
            return False
        
        # 3. ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ” ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸...")
        test_query = "ê°ˆë¹„íƒ•"
        
        start_time = time.time()
        embedding = await adapter._get_embedding_from_ml_service(test_query)
        execution_time = time.time() - start_time
        
        print(f"âœ… ì„ë² ë”© ìƒì„± ì„±ê³µ:")
        print(f"   - ì¿¼ë¦¬: '{test_query}'")
        print(f"   - ì°¨ì›: {len(embedding)}")
        print(f"   - ì‹¤í–‰ì‹œê°„: {execution_time:.3f}ì´ˆ")
        print(f"   - ì„ë² ë”© ë¯¸ë¦¬ë³´ê¸°: {embedding[:5]}")
        
        # 4. íŒ©í† ë¦¬ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
        print("\nğŸ” íŒ©í† ë¦¬ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        from services.recipe.utils.recommend_service import get_db_vector_searcher
        
        searcher = await get_db_vector_searcher()
        print(f"âœ… ë²¡í„° ê²€ìƒ‰ ì–´ëŒ‘í„° ìƒì„± ì„±ê³µ: {type(searcher).__name__}")
        
        # 5. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        print("\nğŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸...")
        print(f"   - ML_MODE: {os.getenv('ML_MODE')}")
        print(f"   - ML_INFERENCE_URL: {os.getenv('ML_INFERENCE_URL')}")
        print(f"   - ML_TIMEOUT: {os.getenv('ML_TIMEOUT')}")
        print(f"   - ML_RETRIES: {os.getenv('ML_RETRIES')}")
        
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
        
    except ImportError as e:
        print(f"âŒ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        print("   - ì˜ì¡´ì„± íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        print("   - httpx íŒ¨í‚¤ì§€: pip install httpx")
        return False
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_local_vs_remote():
    """ë¡œì»¬ ëª¨ë“œì™€ ì›ê²© ëª¨ë“œ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”„ ë¡œì»¬ vs ì›ê²© ëª¨ë“œ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì›ê²© ëª¨ë“œ í…ŒìŠ¤íŠ¸
    print("1ï¸âƒ£ ì›ê²© ëª¨ë“œ í…ŒìŠ¤íŠ¸...")
    os.environ["ML_MODE"] = "remote_embed"
    
    try:
        from services.recipe.utils.recommend_service import get_db_vector_searcher
        remote_searcher = await get_db_vector_searcher()
        print(f"   âœ… ì›ê²© ëª¨ë“œ ì–´ëŒ‘í„°: {type(remote_searcher).__name__}")
    except Exception as e:
        print(f"   âŒ ì›ê²© ëª¨ë“œ ì‹¤íŒ¨: {e}")
    
    # ë¡œì»¬ ëª¨ë“œ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ë¡œì»¬ ëª¨ë“œ í…ŒìŠ¤íŠ¸...")
    os.environ["ML_MODE"] = "local"
    
    try:
        from services.recipe.utils.recommend_service import get_db_vector_searcher
        local_searcher = await get_db_vector_searcher()
        print(f"   âœ… ë¡œì»¬ ëª¨ë“œ ì–´ëŒ‘í„°: {type(local_searcher).__name__}")
    except Exception as e:
        print(f"   âŒ ë¡œì»¬ ëª¨ë“œ ì‹¤íŒ¨: {e}")
    
    print("\nâœ… ëª¨ë“œ ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª ë°±ì—”ë“œ ML ì„œë¹„ìŠ¤ ì—°ë™ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    success = await test_remote_ml_adapter()
    
    if success:
        # ëª¨ë“œ ë¹„êµ í…ŒìŠ¤íŠ¸
        await test_local_vs_remote()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
        print("   1. ML ì„œë¹„ìŠ¤ ì‹¤í–‰: docker-compose --profile with-ml up -d")
        print("   2. ë°±ì—”ë“œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •: ML_MODE=remote_embed")
        print("   3. í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ”§ ë¬¸ì œ í•´ê²°:")
        print("   1. ML ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        print("   2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸")
        print("   3. ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸")

if __name__ == "__main__":
    asyncio.run(main())
